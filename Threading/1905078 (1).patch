diff --git a/Makefile b/Makefile
index 39a99d7..a822569 100644
--- a/Makefile
+++ b/Makefile
@@ -132,6 +132,8 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
+	$U/_threads\
+	$U/_producer_consumer\
 
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..5e6a2c4 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -106,7 +106,10 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
-
+void            proc_freepagetable_for_thread(pagetable_t, uint64);     //offline
+int             thread_create(uint64 fcn,uint64 arg,uint64 stack);  //offline
+int             thread_join(int thread_id);
+void            thread_exit(int);                            //offline
 // swtch.S
 void            swtch(struct context*, struct context*);
 
@@ -173,7 +176,12 @@ uint64          walkaddr(pagetable_t, uint64);
 int             copyout(pagetable_t, uint64, char *, uint64);
 int             copyin(pagetable_t, char *, uint64, uint64);
 int             copyinstr(pagetable_t, char *, uint64, uint64);
-
+int             uvmmirror(pagetable_t, pagetable_t, uint64 sz);
+int             uvmanothermirror(pagetable_t old,pagetable_t new,uint64 oldsize,uint64 newsize);
+void            uvmfree_for_thread(pagetable_t, uint64);
+void            sleepmode(uint64, int);
+uint64          convertvirtophy(pagetable_t pagetable,uint64 vir_a);
+void            wakeupmode(uint64);
 // plic.c
 void            plicinit(void);
 void            plicinithart(void);
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..8c611b0 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -13,7 +13,11 @@ struct proc proc[NPROC];
 struct proc *initproc;
 
 int nextpid = 1;
+int nextmid = 1;
 struct spinlock pid_lock;
+struct spinlock mid_lock[NPROC];
+
+
 
 extern void forkret(void);
 static void freeproc(struct proc *p);
@@ -51,8 +55,12 @@ procinit(void)
   
   initlock(&pid_lock, "nextpid");
   initlock(&wait_lock, "wait_lock");
+
+  int id = 0;
   for(p = proc; p < &proc[NPROC]; p++) {
       initlock(&p->lock, "proc");
+      initlock(&mid_lock[id],"");
+      id++;
       p->state = UNUSED;
       p->kstack = KSTACK((int) (p - proc));
   }
@@ -102,6 +110,21 @@ allocpid()
   return pid;
 }
 
+// //offline
+// int
+// allocmid()
+// {
+//   int memid;
+
+//   acquire(&mid_lock);
+//   memid = nextmid;
+//   nextmid = nextmid + 1;
+//   release(&mid_lock);
+
+//   return memid;
+// }
+
+
 // Look in the process table for an UNUSED proc.
 // If found, initialize state required to run in the kernel,
 // and return with p->lock held.
@@ -111,6 +134,7 @@ allocproc(void)
 {
   struct proc *p;
 
+  int id = 0;
   for(p = proc; p < &proc[NPROC]; p++) {
     acquire(&p->lock);
     if(p->state == UNUSED) {
@@ -118,12 +142,14 @@ allocproc(void)
     } else {
       release(&p->lock);
     }
+    id++;
   }
   return 0;
 
 found:
   p->pid = allocpid();
   p->state = USED;
+  p->mem_id = id;
 
   // Allocate a trapframe page.
   if((p->trapframe = (struct trapframe *)kalloc()) == 0){
@@ -158,11 +184,23 @@ freeproc(struct proc *p)
   if(p->trapframe)
     kfree((void*)p->trapframe);
   p->trapframe = 0;
-  if(p->pagetable)
-    proc_freepagetable(p->pagetable, p->sz);
+  acquire(&mid_lock[p->mem_id]);
+  if(p->pagetable){
+    if (p->is_thread == 0){
+      proc_freepagetable(p->pagetable, p->sz);
+    }
+    else{
+      proc_freepagetable_for_thread(p->pagetable, p->sz);
+
+    }
+    release(&mid_lock[p->mem_id]);
+
+  }
+    //proc_freepagetable(p->pagetable, p->sz);
   p->pagetable = 0;
   p->sz = 0;
   p->pid = 0;
+  p->mem_id = 0;
   p->parent = 0;
   p->name[0] = 0;
   p->chan = 0;
@@ -215,6 +253,16 @@ proc_freepagetable(pagetable_t pagetable, uint64 sz)
   uvmfree(pagetable, sz);
 }
 
+
+void
+proc_freepagetable_for_thread(pagetable_t pagetable, uint64 sz)
+{
+  uvmunmap(pagetable, TRAMPOLINE, 1, 0);
+  uvmunmap(pagetable, TRAPFRAME, 1, 0);
+  uvmfree_for_thread(pagetable, sz);
+}
+
+
 // a user program that calls exec("/init")
 // assembled from ../user/initcode.S
 // od -t xC ../user/initcode
@@ -256,21 +304,53 @@ userinit(void)
 
 // Grow or shrink user memory by n bytes.
 // Return 0 on success, -1 on failure.
+
+
+/* responsible for adjusting the memory allocation of a process and maintaining synchronization and
+memory mirroring between processes with the same memory identifier in a multi-mirror memory management system*/
 int
 growproc(int n)
 {
   uint64 sz;
   struct proc *p = myproc();
 
+  acquire(&mid_lock[p->mem_id]);
   sz = p->sz;
   if(n > 0){
+
     if((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0) {
+      release(&mid_lock[p->mem_id]);
       return -1;
     }
   } else if(n < 0){
     sz = uvmdealloc(p->pagetable, sz, sz + n);
   }
   p->sz = sz;
+  for(struct proc *pr=proc;pr<&proc[NPROC];pr++)
+  {
+    if(pr->mem_id==p->mem_id && pr->pid!=p->pid)
+    {
+      if(n>=0)
+      {
+        uvmanothermirror(pr->pagetable,p->pagetable,pr->sz,p->sz);
+        /*mirror a part of the current process's address space (p) into the address space of the other process (pr).
+        This is likely part of a memory mirroring mechanism to ensure redundancy or distribution of data between processes.*/
+      }
+      else
+      {
+        uint64 newpage=(PGROUNDUP(pr->sz)-PGROUNDUP(sz))/PGSIZE;
+        uvmunmap(pr->pagetable,p->sz,newpage,0);
+
+        /*calculates the number of pages that were removed from the process's address space
+        and unmaps that number of pages from the other process (pr) using uvmunmap.
+        */
+      }
+      pr->sz=sz;
+    }
+  }
+
+  release(&mid_lock[p->mem_id]);
+
   return 0;
 }
 
@@ -325,6 +405,76 @@ fork(void)
   return pid;
 }
 
+
+
+
+int
+thread_create(uint64 fcn,uint64 arg,uint64 stack)
+{
+  int i, pid;
+  struct proc *np;
+  struct proc *p = myproc();
+
+  // Allocate process.
+  if((np = allocproc()) == 0){
+    return -1;
+  }
+
+  // Copy user memory from parent to child.
+  acquire(&mid_lock[p->mem_id]);
+  if(uvmmirror(p->pagetable, np->pagetable, p->sz) < 0){
+    release(&mid_lock[p->mem_id]);
+    freeproc(np);
+    release(&np->lock);
+    return -1;
+  }
+  else{
+    release(&mid_lock[p->mem_id]);
+  }
+  np->sz = p->sz;
+
+
+
+  // copy saved user registers.
+  *(np->trapframe) = *(p->trapframe);
+
+  // Cause fork to return 0 in the child.
+  np->trapframe->a0 = arg;
+  np->trapframe->epc = fcn;
+  np->trapframe->sp = stack + 4096;
+  np->trapframe->sp -= np->trapframe->sp%16;
+  np->is_thread = 1;
+  np->trapframe->ra=0xffffffff; //prevent a process from returning to a valid address
+  //explicitly prevent a process from resuming normal execution.
+
+
+  // increment reference counts on open file descriptors.
+  for(i = 0; i < NOFILE; i++)
+    if(p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  pid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  np->parent = p;
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+
+  acquire(&np->lock);
+  np->mem_id = p->mem_id; //setting paprent's mem_id
+  release(&np->lock);
+
+  return pid;
+}
+
 // Pass p's abandoned children to init.
 // Caller must hold wait_lock.
 void
@@ -385,6 +535,14 @@ exit(int status)
   panic("zombie exit");
 }
 
+
+
+void
+thread_exit(int status)
+{
+  exit(status);
+}
+
 // Wait for a child process to exit and return its pid.
 // Return -1 if this process has no children.
 int
@@ -434,6 +592,54 @@ wait(uint64 addr)
   }
 }
 
+
+int
+thread_join(int thread_id){
+  struct proc *pp;
+  int havekids, pid;
+  struct proc *p = myproc();
+
+  acquire(&wait_lock);
+
+  for(;;){
+    // Scan through table looking for exited children.
+    havekids = 0;
+    for(pp = proc; pp < &proc[NPROC]; pp++){
+      //if(pp->pid == thread_id){
+      if( pp->pid == thread_id && pp->is_thread==1 && p->mem_id == pp->mem_id ){
+        // make sure the child isn't still in exit() or swtch().
+        acquire(&pp->lock);
+
+        havekids = 1;
+        if(pp->state == ZOMBIE){
+          // Found one.
+          pid = pp->pid;
+          // if(addr != 0 && copyout(p->pagetable, addr, (char *)&pp->xstate,
+          //                         sizeof(pp->xstate)) < 0) {
+          //   release(&pp->lock);
+          //   release(&wait_lock);
+          //   return -1;
+          // }
+          freeproc(pp);
+          release(&pp->lock);
+          release(&wait_lock);
+          return pid;
+        }
+        release(&pp->lock);
+      }
+    }
+
+    // No point waiting if we don't have any children.
+    if(!havekids || killed(p)){
+      release(&wait_lock);
+      return -1;
+    }
+
+    // Wait for a child to exit.
+    sleep(p, &wait_lock);  //DOC: wait-sleep
+  }
+}
+
 // Per-CPU process scheduler.
 // Each CPU calls scheduler() after setting itself up.
 // Scheduler never returns.  It loops, doing:
@@ -495,7 +701,9 @@ sched(void)
 
   intena = mycpu()->intena;
   swtch(&p->context, &mycpu()->context);
+  //printf("here sched\n");
   mycpu()->intena = intena;
+
 }
 
 // Give up the CPU for one scheduling round.
@@ -556,11 +764,30 @@ sleep(void *chan, struct spinlock *lk)
   // Tidy up.
   p->chan = 0;
 
+
   // Reacquire original lock.
   release(&p->lock);
   acquire(lk);
 }
 
+
+//offline
+void
+sleepmode(uint64 address, int i){
+  struct proc *p = myproc();
+  acquire(&p->memlock);
+  int* addre = (int*)convertvirtophy(p->pagetable,address);
+
+  if( __sync_bool_compare_and_swap(addre,i,i)){
+      sleep(addre,&p->memlock);
+      release(&p->memlock);
+  }
+  else{
+  release(&p->memlock);
+  }
+  return;
+}
+
 // Wake up all processes sleeping on chan.
 // Must be called without any p->lock.
 void
@@ -571,6 +798,7 @@ wakeup(void *chan)
   for(p = proc; p < &proc[NPROC]; p++) {
     if(p != myproc()){
       acquire(&p->lock);
+      // printf("pid %d\n",p->pid);
       if(p->state == SLEEPING && p->chan == chan) {
         p->state = RUNNABLE;
       }
@@ -579,6 +807,41 @@ wakeup(void *chan)
   }
 }
 
+
+//offline
+void
+wakeupmode(uint64 cv){
+  struct  proc *p = myproc();
+  struct proc *p2;
+  int* address = (int*) convertvirtophy(p->pagetable,cv);
+  //printf("from wakemode %p\n",&address);
+
+  for(p2 = proc; p2 < &proc[NPROC]; p2++) {
+
+    if(p2 != myproc()){
+      //printf("ay\n");
+      //printf("%s\n",p->state);
+      //printf("%s\n",p->chan);
+      // printf("%d\n",p2->mem_id);
+      // printf("%d\n",myproc()->mem_id);
+      acquire(&p2->lock);
+      acquire(&p2->memlock);
+
+      //printf("mem id %d %d\n",p2->mem_id,p->mem_id);
+      if(p2->state == SLEEPING && p2->chan ==(void*) address && p2->mem_id == p->mem_id) { //
+        //printf("pid again %d\n",p2->pid);
+        p2->state = RUNNABLE;
+        release(&p2->memlock);
+        release(&p2->lock);
+        return;
+      }
+      release(&p2->memlock);
+      release(&p2->lock);
+    }
+  }
+
+}
+
 // Kill the process with the given pid.
 // The victim won't exit until it tries to return
 // to user space (see usertrap() in trap.c).
@@ -652,6 +915,9 @@ either_copyin(void *dst, int user_src, uint64 src, uint64 len)
   }
 }
 
+
+
+
 // Print a process listing to console.  For debugging.
 // Runs when user types ^P on console.
 // No lock to avoid wedging a stuck machine further.
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..527543d 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,8 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+  struct spinlock memlock;	// find places to set and release the locks
+  int is_thread;               // if it is thread
+  int mem_id;                   // All threads will have the same physical pages with the mothrer, hence the same memory ID
+
 };
diff --git a/kernel/spinlock.c b/kernel/spinlock.c
index 9840302..aa73333 100644
--- a/kernel/spinlock.c
+++ b/kernel/spinlock.c
@@ -46,8 +46,10 @@ acquire(struct spinlock *lk)
 void
 release(struct spinlock *lk)
 {
-  if(!holding(lk))
+
+  if(!holding(lk)){
     panic("release");
+  }
 
   lk->cpu = 0;
 
@@ -78,6 +80,7 @@ holding(struct spinlock *lk)
 {
   int r;
   r = (lk->locked && lk->cpu == mycpu());
+
   return r;
 }
 
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..d48dfe1 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,12 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_thread_create(void);
+extern uint64 sys_thread_exit(void);
+extern uint64 sys_thread_join(void);
+extern uint64 sys_sleepmode(void);
+extern uint64 sys_wakeupmode(void);
+
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +132,12 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_thread_create]  sys_thread_create,
+[SYS_thread_exit] sys_thread_exit,
+[SYS_thread_join] sys_thread_join,
+[SYS_sleepmode]   sys_sleepmode,
+[SYS_wakeupmode]   sys_wakeupmode,
+
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..384cc4b 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,8 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_thread_create  22
+#define SYS_thread_join  23
+#define SYS_thread_exit  24
+#define SYS_sleepmode 25
+#define SYS_wakeupmode 26
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..7836536 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,55 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+
+uint64
+sys_thread_create(void)
+{
+  uint64 fcn , arg , stack;
+
+  argaddr(0,&fcn);
+  argaddr(1,&arg);
+  argaddr(2,&stack);
+
+  return thread_create(fcn,arg,stack);
+}
+
+uint64
+sys_thread_exit(void)
+{
+  thread_exit(0);
+  return 0;  // not reached
+}
+
+uint64
+sys_thread_join(void)
+{
+  int thread_id;
+
+  argint(0,&thread_id);
+
+  return thread_join(thread_id);
+}
+
+
+uint64
+sys_sleepmode(void)
+{
+  uint64 address;
+  int i;
+
+  argaddr(0,&address);
+  argint(1,&i);
+
+  sleepmode(address,i);
+  return 0;
+}
+
+uint64
+sys_wakeupmode(void){
+  uint64 cv;
+  argaddr(0,&cv);
+  wakeupmode(cv);
+  return 0;
+}
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..c0f25a3 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -6,6 +6,7 @@
 #include "defs.h"
 #include "fs.h"
 
+
 /*
  * the kernel's page table.
  */
@@ -296,6 +297,16 @@ uvmfree(pagetable_t pagetable, uint64 sz)
   freewalk(pagetable);
 }
 
+void
+uvmfree_for_thread(pagetable_t pagetable, uint64 sz)
+{
+  if(sz > 0)
+    uvmunmap(pagetable, 0, PGROUNDUP(sz)/PGSIZE, 0);
+  freewalk(pagetable);
+}
+
+
+
 // Given a parent process's page table, copy
 // its memory into a child's page table.
 // Copies both the page table and the
@@ -332,6 +343,71 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   return -1;
 }
 
+
+
+int
+uvmmirror(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+  //char *mem;
+
+  for(i = 0; i < sz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmmirror: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmmirror: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    // if((mem = kalloc()) == 0)
+    //   goto err;
+    // memmove(mem, (char*)pa, PGSIZE);
+    if(mappages(new, i, PGSIZE, (uint64)pa, flags) != 0){
+      //kfree(pa);
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+
+
+int
+uvmanothermirror(pagetable_t old,pagetable_t new,uint64 oldsize,uint64 newsize)
+{
+  pte_t *pg_table_entry;
+  uint64 page_address;
+  uint64 i;
+  uint flags;
+
+  uint64 old_size=PGROUNDUP(oldsize);
+  uint64 new_size=PGROUNDUP(newsize);
+
+  for(i=old_size;i<new_size;i+=PGSIZE)
+  {
+    /* code */
+    if((pg_table_entry = walk(old, i, 0)) == 0)
+      panic("uvmanothermirror: pte should exist");
+    if((*pg_table_entry & PTE_V) == 0)
+      panic("uvmanothermirror: page not present");
+    page_address = PTE2PA(*pg_table_entry);
+    flags = PTE_FLAGS(*pg_table_entry);
+    if(mappages(new, i, PGSIZE, (uint64)page_address, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+  err:
+    uvmunmap(new,0,i/PGSIZE,1);
+    return -1;
+}
+
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
@@ -395,6 +471,14 @@ copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
   return 0;
 }
 
+uint64
+convertvirtophy(pagetable_t pagetable, uint64 vir_a){
+  uint64 va0, pa0;
+  va0 = PGROUNDDOWN(vir_a);
+  pa0 = walkaddr(pagetable, va0);
+  return pa0+(vir_a-va0);
+}
+
 // Copy a null-terminated string from user to kernel.
 // Copy bytes to dst from virtual address srcva in a given page table,
 // until a '\0', or max.
diff --git a/user/producer_consumer.c b/user/producer_consumer.c
new file mode 100644
index 0000000..05cd8d5
--- /dev/null
+++ b/user/producer_consumer.c
@@ -0,0 +1,135 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/user_lock.h"
+
+struct queue {
+    int arr[16];
+    int front;
+    int rear;
+    int size;
+};
+struct queue q;
+
+
+void queue_push(struct queue *q, int x) {
+    q->arr[q->rear] = x;
+    q->rear = (q->rear + 1) % 16;
+    q->size++;
+}
+
+int queue_front(struct queue *q) {
+    if (q->size == 0) {
+        return -1;
+    }
+    return q->arr[q->front];
+}
+
+void queue_pop(struct queue *q) {
+    q->front = (q->front + 1) % 16;
+    q->size--;
+}
+// a mutex object lock
+struct thread_mutex lock;
+// a semaphore object empty
+struct semaphore empty;
+// a semaphore object full
+struct semaphore full;
+
+
+
+void init_semaphore()
+{
+	// initialize mutex lock
+    thread_mutex_init(&lock);
+	// initialize semaphore empty with 5
+    semaphore_init(&empty,5);
+	// initialize semaphore full with 0
+    semaphore_init(&full,0);
+
+}
+
+void ProducerFunc(void * arg)
+{
+
+	printf("%s\n",(char*)arg);
+    int i;
+	for(i=1;i<=10;i++)
+	{
+		// wait for semphore empty
+        semaphore_wait(&empty);
+        //printf("semaphore wait called\n");
+		// wait for mutex lock
+        thread_mutex_lock(&lock);
+
+		sleep(1);
+		queue_push(&q, i);
+		printf("producer produced item %d\n",i);
+
+		// unlock mutex lock
+        thread_mutex_unlock(&lock);
+		// post semaphore full
+        semaphore_signal(&full);
+	}
+    thread_exit(); // Terminate the thread
+}
+
+void ConsumerFunc(void * arg)
+{
+    printf("%s\n",(char*)arg);
+    int i;
+	for(i=1;i<=10;i++)
+	{
+		// wait for semphore full
+        semaphore_wait(&full);
+        // wait for mutex lock
+		thread_mutex_lock(&lock);
+
+		sleep(1);
+		int item = queue_front(&q);
+        queue_pop(&q);
+		printf("consumer consumed item %d\n",item);
+
+
+		// unlock mutex lock
+        thread_mutex_unlock(&lock);
+		// post semaphore empty
+        semaphore_signal(&empty);
+	}
+    thread_exit(); // Terminate the thread
+}
+
+int main(void)
+{
+
+	init_semaphore();
+
+
+	char * message1 = "i am producer";
+	char * message2 = "i am consumer";
+
+
+	void  *s1,*s2;
+	int thread1, thread2,r1,r2;
+    //int thread2,r2;
+
+	s1 = malloc(4096);
+	s2 = malloc(4096);
+
+
+	thread1 = thread_create(ProducerFunc, (void*)message1, s1);
+    //sleep(1);
+	thread2 = thread_create(ConsumerFunc, (void*)message2, s2);
+
+
+    r1 = thread_join(thread1);
+    r2 = thread_join(thread2);
+
+    printf("Threads finished: (%d):%d, (%d):%d\n",
+      thread1, r1, thread2, r2);
+    // printf("Threads finished:  (%d):%d\n",
+    //    thread2, r2);
+
+
+	exit(0);
+}
diff --git a/user/threads.c b/user/threads.c
new file mode 100644
index 0000000..6397e87
--- /dev/null
+++ b/user/threads.c
@@ -0,0 +1,79 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/user_lock.h"
+
+struct balance {
+    char name[32];
+    int amount;
+};
+
+struct thread_spinlock lock;
+struct thread_mutex mlock;
+
+volatile int total_balance = 0;
+
+volatile unsigned int delay (unsigned int d) {
+   unsigned int i;
+   for (i = 0; i < d; i++) {
+       __asm volatile( "nop" ::: );
+   }
+
+   return i;
+}
+
+void do_work(void *arg){
+    int i;
+    int old;
+
+    struct balance *b = (struct balance*) arg;
+    thread_mutex_lock(&mlock);
+
+    printf( "Starting do_work: s:%s\n", b->name);
+
+    thread_mutex_unlock(&mlock);
+
+    for (i = 0; i < b->amount; i++) {
+        // lock and mlock will be implemented by you.
+         thread_spin_lock(&lock);
+         thread_mutex_lock(&mlock);
+         old = total_balance;
+         delay(100000);
+	 // if(old != total_balance)  printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+         total_balance = old + 1;
+         thread_spin_unlock(&lock);
+         thread_mutex_unlock(&mlock);
+
+    }
+
+    printf( "Done s:%x\n", b->name);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[]) {
+
+  thread_spin_init(&lock, "spin");
+  thread_mutex_init(&mlock);
+
+  struct balance b1 = {"b1", 3200};
+  struct balance b2 = {"b2", 2800};
+
+  void *s1, *s2;
+  int thread1, thread2, r1, r2;
+
+  s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+  s2 = malloc(4096);
+
+  thread1 = thread_create(do_work, (void*)&b1, s1);
+  thread2 = thread_create(do_work, (void*)&b2, s2);
+
+  r1 = thread_join(thread1);
+  r2 = thread_join(thread2);
+
+  printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d\n",
+      thread1, r1, thread2, r2, total_balance);
+
+  exit(0);
+}
\ No newline at end of file
diff --git a/user/user.h b/user/user.h
index 4d398d5..de442b9 100644
--- a/user/user.h
+++ b/user/user.h
@@ -1,3 +1,4 @@
+//#include <cstdint>
 struct stat;
 
 // system calls
@@ -22,6 +23,11 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int thread_create(void(*fcn)(void*), void *arg, void*stack);
+int thread_join(int thread_id);
+void thread_exit(void);
+void sleepmode(int*,int);
+void wakeupmode(int*);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/user_lock.h b/user/user_lock.h
new file mode 100644
index 0000000..55e6039
--- /dev/null
+++ b/user/user_lock.h
@@ -0,0 +1,218 @@
+// Mutual exclusion spin locks.
+
+#include "kernel/types.h"
+#include "kernel/param.h"
+#include "kernel/memlayout.h"
+#include "kernel/riscv.h"
+#include "user.h"
+// Mutual exclusion lock.
+struct thread_spinlock {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+  int pid;
+};
+
+
+void
+thread_spin_init(struct thread_spinlock *lk, char *name)
+{
+  lk->name = name;
+  lk->locked = 0;
+  lk->pid = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_spin_lock(struct thread_spinlock *lk)
+{
+
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    ;
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  //lk->cpu = mycpu();
+  lk->pid = getpid();
+}
+
+// Release the lock.
+void
+thread_spin_unlock(struct thread_spinlock *lk)
+{
+
+  lk->pid = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+
+
+}
+
+// Check whether this cpu is holding the lock.
+// Interrupts must be off.
+
+
+
+
+
+// Mutual exclusion lock.
+struct thread_mutex {
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+  int pid;
+};
+
+
+void
+thread_mutex_init(struct thread_mutex *lk)
+{
+  lk->locked = 0;
+  lk->pid = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_mutex_lock(struct thread_mutex *lk)
+{
+
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    {
+        sleep(1);
+    }
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  //lk->cpu = mycpu();
+  lk->pid = getpid();
+}
+
+// Release the lock.
+void
+thread_mutex_unlock(struct thread_mutex *lk)
+{
+   lk->pid = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+
+
+}
+
+// Check whether this cpu is holding the lock.
+// Interrupts must be off.
+
+struct condi{
+    int sig;
+};
+
+void
+pthread_cond_init(struct condi *cv){
+    cv->sig = 0;
+}
+
+void
+pthread_cond_wait(struct condi *cv,struct thread_mutex *mu){
+    __sync_fetch_and_add(&cv->sig,0); //cv->sig value set to 0
+
+    thread_mutex_unlock(mu);
+    while (__sync_bool_compare_and_swap(&cv->sig,0,0)!=0) //waiting
+    {
+        sleepmode(&cv->sig,0);
+    }
+
+    thread_mutex_lock(mu);
+}
+
+void
+pthread_cond_signal(struct condi *cv){
+    __sync_fetch_and_or(&cv->sig,1);
+    //printf("pthread_cond_signal_1\n");
+    wakeupmode(&cv->sig);
+    //printf("pthread_cond_signal_2\n");
+
+    return;
+}
+
+void
+pthread_cond_broadcast(struct condi *cv){
+    __sync_fetch_and_or(&cv->sig,64);
+    //printf("pthread_cond_signal_1\n");
+    wakeupmode(&cv->sig);
+    //printf("pthread_cond_signal_2\n");
+
+    return;
+}
+
+
+struct semaphore {
+    struct condi cv;
+    struct thread_mutex mu;
+    int count;
+};
+
+void semaphore_init(struct semaphore *sem, int initialValue) {
+    pthread_cond_init(&sem->cv);
+    thread_mutex_init(&sem->mu);
+    sem->count = initialValue;
+}
+
+void semaphore_wait(struct semaphore *sem) {
+    thread_mutex_lock(&sem->mu);
+    while (sem->count == 0) {
+        pthread_cond_wait(&sem->cv, &sem->mu);
+    }
+    sem->count--; // Decrement the semaphore count
+    thread_mutex_unlock(&sem->mu);
+}
+
+void semaphore_signal(struct semaphore *sem) {
+    //printf("semaphore _signal called\n");
+    thread_mutex_lock(&sem->mu);
+    sem->count++; // Increment the semaphore count
+    pthread_cond_signal(&sem->cv);
+    thread_mutex_unlock(&sem->mu);
+}
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..c100ed2 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,8 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("thread_create");
+entry("thread_join");
+entry("thread_exit");
+entry("sleepmode");
+entry("wakeupmode");
\ No newline at end of file
